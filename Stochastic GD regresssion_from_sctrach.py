# -*- coding: utf-8 -*-
"""SGDRegresssion From Sctrach.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1qhWIgdq1_oYytC-g6PiHmu8iUNFisY41
"""

from sklearn.datasets import load_diabetes

import numpy as np
import pandas as pd
from sklearn.linear_model import LinearRegression
from sklearn.model_selection import train_test_split

x,y=load_diabetes(return_X_y=True)

print(x.shape)

print(y.shape)

x_train,x_test,y_train,y_test=train_test_split(x,y,test_size=0.2,random_state=12)

reg=LinearRegression()

reg.fit(x_train,y_train)

from sklearn.metrics import r2_score

reg.intercept_

reg.coef_

r2_score(y_test,reg.predict(x_test))

x.shape

class SGDRegression:
  def __init__(self,epoch=100,lr=0.01):
    self.coef=None
    self.intercept=None
    self.lr=lr
    self.epoch=epoch
    t0,t1=5,50
  def learning_rate(self,t):
    return self.t0/(t+self.t1)
  def fit(self,x,y):
    n=x.shape[0]
    self.intercept=0
    self.coef=np.ones(x.shape[1])  #(mX1) matrix
    print(self.coef.shape)
    #print(self.coef.shape)
    for i in range(self.epoch):
      for j in range(x.shape[0]):
        lr=self.learning_rate(i*x.shape[0]+j)
        #j=np.random.randint(0,self.epoch)
        #print(x[j].shape)
        y_pred=self.intercept+np.dot(self.coef,x[j])
        #update all the coefs and the intercept
        intercept_slope=-2*(y[j]-y_pred)
        self.intercept=self.intercept-self.lr*intercept_slope
        coef_slope=-2*(np.dot((y[j]-y_pred),x[j]))
        self.coef=self.coef-(self.lr*coef_slope)
  def predict(self,x):
    return self.intercept+np.dot(x,self.coef)

gdr=SGDRegression()

gdr.fit(x_train,y_train)

gdr.intercept

reg.intercept_

gdr.coef

y_pred=gdr.predict(x_test)

y_pred

r2_score(y_test,y_pred)

#OLS method: 38% accuracy
#Stochastic Gradient Descent method: 37.4% accuracy

"""normal GD needed 3000 epoch to get the result but sgd took only 100, which can be further optimized using hyperparameter tuning"""

